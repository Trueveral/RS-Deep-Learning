{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AlbertTokenizerFast, AlbertModel\n",
    "# from gensim.models import Word2Vec\n",
    "# from nets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html\n",
    "class GloveEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding()\n",
    "        self.unknown_idx = 0\n",
    "        # a dictionary like {'best':1} from idx_to_token\n",
    "        self.token_to_idx = {\n",
    "            token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = '../../Datasets/Model/nlp/'\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), encoding='gb18030', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                # structure: hello  [0.1, 0.2, 0.3, ...]\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [\n",
    "            self.token_to_idx.get(token, self.unknown_idx)\n",
    "            for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CONSTANTS'''\n",
    "batch_size = 32\n",
    "max_epoch = 40\n",
    "lr = 0.001\n",
    "\n",
    "LD = 30\n",
    "LW = 20\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "train_data_path = '../../Datasets/Model/train'\n",
    "test_data_path = '../../Datasets/Model/test'\n",
    "image_path = '../../Datasets/Images'\n",
    "data_save_path = '../../Save/Experiment5'\n",
    "analytics_path = '../../Analysis/Experiment5'\n",
    "nlp_path = '../../Datasets/Model/nlp'\n",
    "\n",
    "'''NLP'''\n",
    "# load word2vec models from nlp_path\n",
    "# model_review = Word2Vec.load(f'{nlp_path}/model_review.model')\n",
    "# model_title = Word2Vec.load(f'{nlp_path}/model_title.model')\n",
    "\n",
    "# get the vocabulary of reviews titles\n",
    "# vocab_review = model_review.wv.index_to_key\n",
    "# vocab_title = model_title.wv.index_to_key\n",
    "\n",
    "# # get the vectors of reviews and titles\n",
    "# vecs_review = torch.tensor(model_review.wv[vocab_review])\n",
    "# vecs_title = torch.tensor(model_title.wv[vocab_title])\n",
    "\n",
    "# get the glove embeddings\n",
    "# print(\"Loading glove embeddings...\")\n",
    "# glove = GloveEmbedding()\n",
    "\n",
    "\n",
    "'''ANALYTICS'''\n",
    "\n",
    "rmse_arr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = np.load(f'{train_data_path}/train_users.npy')\n",
    "train_items = np.load(f'{train_data_path}/train_items.npy')\n",
    "train_ratings = np.load(f'{train_data_path}/train_ratings.npy')\n",
    "train_reviews = np.load(\n",
    "    f'{train_data_path}/train_reviews.npy', allow_pickle=True)\n",
    "train_descriptions = np.load(\n",
    "    f'{train_data_path}/train_descriptions.npy', allow_pickle=True)\n",
    "train_titles = np.load(\n",
    "    f'{train_data_path}/train_titles.npy', allow_pickle=True)\n",
    "train_prices = np.load(f'{train_data_path}/train_prices.npy')\n",
    "train_categories = np.load(f'{train_data_path}/train_categories.npy')\n",
    "\n",
    "test_users = np.load(f'{test_data_path}/test_users.npy')\n",
    "test_items = np.load(f'{test_data_path}/test_items.npy')\n",
    "test_ratings = np.load(f'{test_data_path}/test_ratings.npy')\n",
    "test_reviews = np.load(f'{test_data_path}/test_reviews.npy', allow_pickle=True)\n",
    "test_descriptions = np.load(\n",
    "    f'{test_data_path}/test_descriptions.npy', allow_pickle=True)\n",
    "test_titles = np.load(\n",
    "    f'{test_data_path}/test_titles.npy', allow_pickle=True)\n",
    "test_prices = np.load(f'{test_data_path}/test_prices.npy')\n",
    "test_categories = np.load(f'{test_data_path}/test_categories.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72693"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function accepts a sequence, and pads the setences in the sequence to LW length, then returns the padded sequence\n",
    "def pad_sequence(sequence, lw = LW, ld = LD, placeholder=0):\n",
    "    arr = []\n",
    "    for sentence in sequence:\n",
    "      if len(sentence) < lw:\n",
    "        arr.append(sentence + [placeholder] * (lw - len(sentence)))\n",
    "      else:\n",
    "        arr.append(sentence[:lw])\n",
    "\n",
    "    if len(arr) > ld:\n",
    "      arr = arr[:ld]\n",
    "    else:\n",
    "      for i in range (ld-len(arr)):\n",
    "        arr.append([placeholder] * lw)\n",
    "        \n",
    "    return arr\n",
    "\n",
    "'''sample user'''\n",
    "'''this function takes a user, who is from a set of users, a set of items, a set of reviews, a set of titles, \n",
    "a set of categories, a set of prices, and a set of ratings.'''\n",
    "def sample_user(user, users, items, reviews, ratings):\n",
    "  # find out all the indicies of the user in users\n",
    "  user_indices = np.where(users == user)[0]\n",
    "  # randomly select an index from these indicies.\n",
    "  user_index = np.random.choice(user_indices)\n",
    "\n",
    "  # get the item that the user has purchased.\n",
    "  item = items[user_index]\n",
    "\n",
    "  # get the rating that the user has given to that item.\n",
    "  rating = ratings[user_index]\n",
    "\n",
    "  # find out the indices of the item in items\n",
    "  item_indices = np.where(items == item)[0]\n",
    "\n",
    "  # get the reviews of that item\n",
    "  item_reviews = [reviews[i] for i in item_indices if i != user_index]\n",
    "  user_reviews = [reviews[i] for i in user_indices if i != user_index]\n",
    "\n",
    "  user_reviews = pad_sequence(user_reviews)\n",
    "  item_reviews = pad_sequence(item_reviews)\n",
    "\n",
    "  return user, item, rating, item_reviews, user_reviews\n",
    "\n",
    "\n",
    "'''function to get a batch of training samples.\n",
    "this function selects a random user from a set of users\n",
    "and gets his information by function sample_user, repeat it for batch_size times and \n",
    "gets the batch of samples. Each element in the batch tuple is then transormed to a pytorch tensor and returned.'''\n",
    "def get_batch(users, items, reviews, ratings, batch_size=32, fixed_users_set = None):\n",
    "  # get a batch of users\n",
    "  if fixed_users_set is None:\n",
    "    batch_users = np.random.choice(users, size=batch_size)\n",
    "  else:\n",
    "    batch_users = fixed_users_set\n",
    "  # get the batch of samples\n",
    "  batch = [list(sample_user(user, users, items, reviews, ratings)) for user in batch_users]\n",
    "  # transform each column of the batch to a pytorch tensor\n",
    "  batch = [torch.tensor(sample) for sample in zip(*batch)]\n",
    "  return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training samples\n",
    "batch = get_batch(train_users, train_items, train_reviews, train_ratings)\n",
    "user, item, rating, item_reviews, user_reviews = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.normal_(m.weight.data)\n",
    "    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class FM(nn.Module):\n",
    "    def __init__(self, latent_dim, fea_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.w0 = nn.Parameter(torch.zeros([1, ], requires_grad=True))\n",
    "        self.w1 = nn.Parameter(torch.rand([fea_num, 1], requires_grad=True))\n",
    "        self.w2 = nn.Parameter(torch.rand([fea_num, latent_dim], requires_grad=True))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs = inputs.long()\n",
    "        first_order = self.w0 + torch.mm(inputs, self.w1)\n",
    "        second_order = 1/2 * torch.sum(\n",
    "            torch.pow(torch.mm(inputs, self.w2), 2) -\n",
    "            torch.mm(torch.pow(inputs, 2), torch.pow(self.w2, 2)),\n",
    "\n",
    "            dim=1,\n",
    "            keepdim=True\n",
    "        )\n",
    "\n",
    "        return first_order + second_order\n",
    "\n",
    "\n",
    "class MPCN(nn.Module):\n",
    "  def __init__(self, vocab_size = 100000, embed_size = 50, lw = LW, fm_dim = 8, np=1):\n",
    "      super().__init__()\n",
    "      self.np = np\n",
    "      self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "      # initialise a weighting matrix of size (50 x 50)\n",
    "      self.W_g = nn.Parameter(torch.rand(embed_size, embed_size, requires_grad=True) * 0.001)\n",
    "      # initialise a bias vector of size (50)\n",
    "      self.b_g = nn.Parameter(torch.zeros(embed_size, requires_grad=True))\n",
    "      # initialise a weighting matrix of size (50 x 50)\n",
    "      self.W_u = nn.Parameter(torch.rand(embed_size, embed_size, requires_grad=True) * 0.001)\n",
    "      # initialise a bias vector of size (50)\n",
    "      self.b_u = nn.Parameter(torch.zeros(embed_size, requires_grad=True))\n",
    "      self.sigmoid = nn.Sigmoid()\n",
    "      self.tanh = nn.Tanh()\n",
    "\n",
    "      self.F_review = nn.Sequential(\n",
    "        nn.Linear(embed_size, 2*embed_size, bias=True),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(2*embed_size, embed_size, bias=True),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Dropout(0.2),\n",
    "      )\n",
    "\n",
    "      self.F_word = nn.Sequential(\n",
    "        nn.Linear(embed_size, 2*embed_size, bias=True),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(2*embed_size, embed_size, bias=True),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Dropout(0.2),\n",
    "      )\n",
    "\n",
    "      # initialise a weighting matrix of size (50 x 50)\n",
    "      self.M = nn.Parameter(torch.rand(embed_size, embed_size, requires_grad=True) * 0.001)\n",
    "      self.M_w = nn.Parameter(torch.rand(embed_size, embed_size, requires_grad=True) * 0.001)\n",
    "\n",
    "      self.fm = FM(fm_dim, 2 * embed_size)\n",
    "\n",
    "  def forward(self, a, b):\n",
    "    a = self.embedding(a.long())\n",
    "    b = self.embedding(b.long())\n",
    "    # size of a: (32, 30, 20, 50)\n",
    "    # size of b: (32, 30, 20, 50)\n",
    "\n",
    "    a_sumed = torch.sum(a, dim=2)\n",
    "    b_sumed = torch.sum(b, dim=2)\n",
    "    # size of a_sumed: (32, 30, 50)\n",
    "    # size of b_sumed: (32, 30, 50)\n",
    "\n",
    "    a_bar = self.sigmoid(a_sumed @ self.W_u) + self.b_g * self.tanh(a_sumed @ self.W_g + self.b_u)\n",
    "    b_bar = self.sigmoid(b_sumed @ self.W_u) + self.b_g * self.tanh(b_sumed @ self.W_g + self.b_u)\n",
    "    # size of a_bar: (32, 30, 50)\n",
    "    # size of b_bar: (32, 30, 50)\n",
    "\n",
    "    a_prime_arr = []\n",
    "    b_prime_arr = []\n",
    "\n",
    "\n",
    "    for i in range (self.np):\n",
    "      S = self.F_review(a_bar) @ self.M @ self.F_review(b_bar).permute(0,2,1)\n",
    "      # get the maximum of S columnwise\n",
    "      max_col_S = torch.max(S, dim=1)[0]\n",
    "      # get the maximum of S rowwise\n",
    "      max_row_S = torch.max(S, dim=2)[0]\n",
    "\n",
    "      # size of S: (32, 30, 30)\n",
    "      # size of max_col_S: (32, 30)\n",
    "      # size of max_row_S: (32, 30)\n",
    "\n",
    "      p_a = nn.functional.gumbel_softmax(logits=max_col_S, hard=True, dim=-1, tau=0.1).unsqueeze(1).unsqueeze(2)\n",
    "      p_b = nn.functional.gumbel_softmax(logits=max_row_S, hard=True, dim=-1, tau=0.1).unsqueeze(1).unsqueeze(2)\n",
    "      # size of p_a: (32, 1, 1, 30)\n",
    "      # size of p_b: (32, 1, 1, 30)\n",
    "\n",
    "      ''' This step implements the pointer selection mechanism in the paper \n",
    "      \n",
    "      p_a is originally a two-dimensional tensor of size (32 x 30(LW)), while a, b \\\n",
    "      are originally a four-dimensional tensor of size (32 x 30(LW) x 20 x 50) \\\n",
    "      we need to reshape p_a and p_b to a four-dimensional tensor of size (32, 1, 1, 30) \\\n",
    "      and multiply with reshaped a and b to (32, 20, 30, 50) (a.permute(0,2,1,3)) \\\n",
    "      then we get the correct but not ideally-shaped selected review of size a' = (32, 1, 20, 50) \\\n",
    "      then we squeeze the second dimension (a'.squeeze(1)) of a' to get (32, 20, 50)\n",
    "      \n",
    "      ''' \n",
    "\n",
    "      a_prime = (p_a @ a.permute(0,2,1,3)).permute(0,2,1,3).squeeze(1)\n",
    "      b_prime = (p_b @ b.permute(0,2,1,3)).permute(0,2,1,3).squeeze(1)\n",
    "      # size of a_prime: (32, 20, 50)\n",
    "      # size of b_prime: (32, 20, 50)\n",
    "\n",
    "      a_prime_arr.append(a_prime)\n",
    "      b_prime_arr.append(b_prime)\n",
    "    \n",
    "    a_prime = torch.cat(a_prime_arr, dim=1)\n",
    "    b_prime = torch.cat(b_prime_arr, dim=1)\n",
    "    \n",
    "    W = self.F_word(a_prime) @ self.M_w @ self.F_word(b_prime).permute(0,2,1)\n",
    "    # size of W: (32, 20, 20)\n",
    "\n",
    "    # get the column average of W\n",
    "    avg_col_W = torch.mean(W, dim=1).unsqueeze(2)\n",
    "    # get the row average of W\n",
    "    avg_row_W = torch.mean(W, dim=2).unsqueeze(2)\n",
    "    # size of avg_col_W: (32, 20, 1)\n",
    "    # size of avg_row_W: (32, 20, 1)\n",
    "    \n",
    "    a_bar_prime = self.sigmoid(avg_col_W).permute(0,2,1) @ a_prime\n",
    "    b_bar_prime = self.sigmoid(avg_row_W).permute(0,2,1) @ a_prime\n",
    "    # size of a_bar_prime: (32, 1, 50)\n",
    "    # size of b_bar_prime: (32, 1, 50)\n",
    "\n",
    "    a_bar_prime = a_bar_prime.squeeze(1)\n",
    "    b_bar_prime = b_bar_prime.squeeze(1)\n",
    "\n",
    "    # concatenate a_bar_prime and b_bar_prime\n",
    "    a_bar_prime_bar_prime = torch.cat((a_bar_prime, b_bar_prime), dim=1)\n",
    "    \n",
    "    pred = self.fm(a_bar_prime_bar_prime)\n",
    "\n",
    "    # flatten the predictions\n",
    "    pred = pred.squeeze(1)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpcn = MPCN().apply(weights_init).to(device)\n",
    "optimiser_mpcn = optim.Adam(mpcn.parameters(), lr=lr, weight_decay=1e-6)\n",
    "\n",
    "def save_training(path = f'{data_save_path}/'):\n",
    "  torch.save(mpcn.state_dict(), path + 'mpcn_p1.pt')\n",
    "  torch.save(optimiser_mpcn.state_dict(), path + 'mpcn_optimiser_p1.pt')\n",
    "  print('Saved model and optimiser')\n",
    "\n",
    "def load_training(path = f'{data_save_path}/'):\n",
    "  mpcn.load_state_dict(torch.load(path + 'mpcn_p1.pt'))\n",
    "  optimiser_mpcn.load_state_dict(torch.load(path + 'mpcn_optimiser_p1.pt'))\n",
    "  print('Loaded model and optimiser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program: Evaluating the baseline RMSE of the model on the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3609/3609 [00:50<00:00, 71.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 75946.78736860107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:39<00:00, 25.08it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 76.77606964111328 Test RMSE: 9.191558181628457\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.54it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 51.792236328125 Test RMSE: 9.12858437831199\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.24it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 58.2535285949707 Test RMSE: 8.980988143256049\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:45<00:00, 21.79it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 69.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 46.702999114990234 Test RMSE: 8.809405372426198\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 21.22it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 69.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 48.55809783935547 Test RMSE: 8.509257124084025\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.30it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 69.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 80.8758316040039 Test RMSE: 8.078837707320815\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 21.20it/s]\n",
      "100%|██████████| 3609/3609 [00:53<00:00, 67.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 22.8789005279541 Test RMSE: 7.509134194698317\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:50<00:00, 19.74it/s]\n",
      "100%|██████████| 3609/3609 [00:53<00:00, 67.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 43.264312744140625 Test RMSE: 6.807350507301781\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:48<00:00, 20.65it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 69.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 21.539663314819336 Test RMSE: 6.011502061533644\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:48<00:00, 20.56it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 69.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 16.237194061279297 Test RMSE: 5.1289220010187195\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:51<00:00, 19.59it/s]\n",
      "100%|██████████| 3609/3609 [00:54<00:00, 66.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Loss: 26.205860137939453 Test RMSE: 4.3814976259624245\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:52<00:00, 19.20it/s]\n",
      "100%|██████████| 3609/3609 [00:53<00:00, 67.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Loss: 10.669622421264648 Test RMSE: 3.7602816370591197\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:48<00:00, 20.60it/s]\n",
      "100%|██████████| 3609/3609 [00:51<00:00, 69.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Loss: 11.032804489135742 Test RMSE: 3.2503493194535156\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 20.85it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Loss: 6.958337783813477 Test RMSE: 2.7904270704052196\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.43it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Loss: 6.801729202270508 Test RMSE: 2.3982462077697053\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.54it/s]\n",
      "100%|██████████| 3609/3609 [00:54<00:00, 66.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Loss: 3.0354135036468506 Test RMSE: 2.0478683387053973\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 21.11it/s]\n",
      "100%|██████████| 3609/3609 [00:53<00:00, 67.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Loss: 3.202101230621338 Test RMSE: 1.750325412458249\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:45<00:00, 21.94it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Loss: 2.6582107543945312 Test RMSE: 1.522259560094444\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.45it/s]\n",
      "100%|██████████| 3609/3609 [00:52<00:00, 68.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Loss: 1.5081747770309448 Test RMSE: 1.3645203058063637\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.54it/s]\n",
      "100%|██████████| 3609/3609 [00:54<00:00, 66.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Loss: 1.3674492835998535 Test RMSE: 1.2774402344448146\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 20.97it/s]\n",
      "100%|██████████| 3609/3609 [00:59<00:00, 60.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Loss: 0.6865288615226746 Test RMSE: 1.2252992186958553\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:55<00:00, 17.89it/s]\n",
      "100%|██████████| 3609/3609 [01:37<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 Loss: 0.9622846841812134 Test RMSE: 1.1961677449665826\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 21.02it/s]\n",
      "100%|██████████| 3609/3609 [00:59<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Loss: 1.1682018041610718 Test RMSE: 1.1791307386945047\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.47it/s]\n",
      "100%|██████████| 3609/3609 [00:56<00:00, 64.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 Loss: 1.6222376823425293 Test RMSE: 1.1709497803860869\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:48<00:00, 20.45it/s]\n",
      "100%|██████████| 3609/3609 [00:54<00:00, 65.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 Loss: 1.2204010486602783 Test RMSE: 1.1661413172401858\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:51<00:00, 19.47it/s]\n",
      "100%|██████████| 3609/3609 [00:58<00:00, 61.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 Loss: 2.398012638092041 Test RMSE: 1.165182668834421\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.25it/s]\n",
      "100%|██████████| 3609/3609 [00:57<00:00, 62.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Loss: 1.423048973083496 Test RMSE: 1.1584745205713791\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:55<00:00, 18.07it/s]\n",
      "100%|██████████| 3609/3609 [00:59<00:00, 60.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 Loss: 1.569369912147522 Test RMSE: 1.1592630117215024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:57<00:00, 17.43it/s]\n",
      "100%|██████████| 3609/3609 [00:58<00:00, 61.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 Loss: 2.2177889347076416 Test RMSE: 1.1612308825869149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:00<00:00, 16.49it/s]\n",
      "100%|██████████| 3609/3609 [01:03<00:00, 57.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 Loss: 0.7678495645523071 Test RMSE: 1.15956270704642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:59<00:00, 16.75it/s]\n",
      "100%|██████████| 3609/3609 [01:02<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 Loss: 1.4699289798736572 Test RMSE: 1.1588731743550162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:02<00:00, 16.02it/s]\n",
      "100%|██████████| 3609/3609 [01:02<00:00, 58.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 Loss: 1.5873441696166992 Test RMSE: 1.1584311540716736\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:58<00:00, 16.97it/s]\n",
      "100%|██████████| 3609/3609 [01:02<00:00, 57.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 Loss: 1.1848869323730469 Test RMSE: 1.1591184049076768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:52<00:00, 19.12it/s]\n",
      "100%|██████████| 3609/3609 [00:54<00:00, 66.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 Loss: 1.671623945236206 Test RMSE: 1.1559729854563128\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:45<00:00, 21.89it/s]\n",
      "100%|██████████| 3609/3609 [00:48<00:00, 74.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Loss: 0.9866482019424438 Test RMSE: 1.1618963089567962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:41<00:00, 24.11it/s]\n",
      "100%|██████████| 3609/3609 [00:49<00:00, 73.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 Loss: 1.6508545875549316 Test RMSE: 1.159894377942824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.70it/s]\n",
      "100%|██████████| 3609/3609 [00:48<00:00, 73.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 Loss: 1.4856376647949219 Test RMSE: 1.157024210048997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:41<00:00, 23.88it/s]\n",
      "100%|██████████| 3609/3609 [00:49<00:00, 72.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 2.0190165042877197 Test RMSE: 1.1592120213599773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:42<00:00, 23.67it/s]\n",
      "100%|██████████| 3609/3609 [00:48<00:00, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 Loss: 1.711219072341919 Test RMSE: 1.15599971659529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:43<00:00, 23.08it/s]\n",
      "100%|██████████| 3609/3609 [00:48<00:00, 74.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 Loss: 1.41908860206604 Test RMSE: 1.1558816255410644\n",
      "Saved model and optimiser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Training'''\n",
    "RMSE = []\n",
    "best_rmse = 1e6\n",
    "\n",
    "def evaluation(test_batch_size = 32):\n",
    "  test_users_unique = list(set(test_users))\n",
    "  rmse_arr = []\n",
    "  for i in tqdm(range(0, len(test_users_unique), test_batch_size)):\n",
    "    test_users_batch = test_users_unique[i:i+test_batch_size]\n",
    "    batch_test = get_batch(test_users, test_items, test_reviews, test_ratings, fixed_users_set=test_users_batch)\n",
    "    user, item, rating, item_reviews, user_reviews = batch_test\n",
    "    user, item, rating, item_reviews, user_reviews = user.to(device), item.to(device), rating.to(device), item_reviews.to(device), user_reviews.to(device)\n",
    "\n",
    "    pred = mpcn(item_reviews, user_reviews)\n",
    "\n",
    "    # calculate rooted mean square error\n",
    "    rmse_arr.append(torch.sqrt(torch.mean((pred - rating)**2)).item())\n",
    "  \n",
    "  # return the mean of the rmse_arr\n",
    "  return np.mean(rmse_arr)\n",
    "\n",
    "print(\"Program: Evaluating the baseline RMSE of the model on the test set\")\n",
    "\n",
    "# set best_rmse to be the largest possible value\n",
    "best_rmse = evaluation()\n",
    "RMSE.append(best_rmse)\n",
    "\n",
    "# print baseline best_rmse\n",
    "print('Baseline RMSE:', best_rmse)\n",
    "\n",
    "for epoch in range (max_epoch):\n",
    "  for i in tqdm(range(1000)):\n",
    "    batch =  get_batch(train_users, train_items, train_reviews, train_ratings)\n",
    "    user, item, rating, item_reviews, user_reviews = batch\n",
    "    user, item, rating, item_reviews, user_reviews = user.to(device), item.to(device), rating.to(device), item_reviews.to(device), user_reviews.to(device)\n",
    "\n",
    "    pred = mpcn(item_reviews, user_reviews)\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = torch.mean((pred - rating)**2)\n",
    "\n",
    "    optimiser_mpcn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser_mpcn.step()\n",
    "\n",
    "  '''evaluate the model on the test set'''\n",
    "  rmse_test = evaluation()\n",
    "  RMSE.append(rmse_test)\n",
    "  # print out the loss of the models and the test rmse\n",
    "  print('Epoch:', epoch, 'Loss:', loss.item(), 'Test RMSE:', rmse_test)\n",
    "  if rmse_test < best_rmse:\n",
    "    best_rmse = rmse_test\n",
    "    save_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f'{analytics_path}/rmse_p1.txt', 'w') as f:\n",
    "  for r in RMSE:\n",
    "    f.write(str(np.round(r, 4)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('y3project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af667c24e890afcb270fe85ca560e1aa788703788da50f20e13467161b45801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
